{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Libraries**\n",
        "\n"
      ],
      "metadata": {
        "id": "nFxTx7SaoVs_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "5kduHN6xD-oR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset**\n",
        "*   Code sample written in Python\n",
        "*   label '1' - code sample is considered correct.\n",
        "*   label '0' - code sample is considered incorrect.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7zTuNKlOoobV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "code_samples = [\n",
        "    \"for i in range(10):\\n    print(i)\",\n",
        "    \"while True:\\n    print('Hello, World!')\",\n",
        "    \"print('Hello, World'\",\n",
        "    \"def my_function():\\n    print('Function is working!'\\n\",\n",
        "    \"print('hello world')\",\n",
        "    \"while 1:\\n\",\n",
        "    \"if x > 0:\\n    print('x is positive')\",\n",
        "    \"for item in my_list:\\n    process_item(item)\",\n",
        "    \"while condition:\\n    do_something()\",\n",
        "    \"def calculate_sum(a, b):\\n    return a + b\",\n",
        "    \"print('Hello, World')\",\n",
        "    \"for i in range(5):\\nprint(i)\",\n",
        "    \"while True:\\n    print('Infinite loop')\",\n",
        "    \"if a < 10:\\n    print('a is less than 10'\",\n",
        "    \"for i in range(5):\\n    print(i)\",\n",
        "    \"if condition:\\n    do_something()\",\n",
        "    \"def my_function(param1, param2):\\n    return param1 + param2\",\n",
        "    \"while x > 0:\\n    x -= 1\",\n",
        "    \"print('This is a test message')\",\n",
        "    \"for i in range(10):\\n  print(i)\",\n",
        "    \"if a == 5:\\n    print('a is equal to 5')\",\n",
        "    \"while True:\\n    print('Infinite loop')\",\n",
        "    \"print('Hello, World!')\",\n",
        "    \"if x < 0:\\n    print('x is negative')\",\n",
        "    \"for item in items:\\n    process_item(item)\",\n",
        "    \"def factorial(n):\\n    if n == 0:\\n        return 1\\n    else:\\n        return n * factorial(n - 1)\",\n",
        "    \"while count > 0:\\n    count -= 1\",\n",
        "    \"print('This is another test message')\",\n",
        "    \"def my_function():\\n    if condition:\\n        return 'True'\\n    else:\\n        return 'False'\",\n",
        "    \"for i in range(3):\\n    print(i)\",\n",
        "    \"if a != 10:\\n    print('a is not equal to 10')\",\n",
        "    \"while x < 100:\\n    x += 10\",\n",
        "    \"print('Welcome to the world of coding!')\",\n",
        "    \"if condition:\\n    print('Condition is true')\",\n",
        "    \"for item in range(5):\\n    print(item)\",\n",
        "    \"def greet(name):\\n    print('Hello, ' + name)\",\n",
        "    \"while i < 10:\\n    i += 1\",\n",
        "    \"print('This is yet another test message')\",\n",
        "    \"def my_function(x, y):\\n    return x + y\",\n",
        "    \"for i in range(3):\\n    print(i)\",\n",
        "    \"if a != 42:\\n    print('a is not the answer to everything')\",\n",
        "    \"while x < 1000:\\n    x += 100\",\n",
        "    \"print('Code examples are fun!')\",\n",
        "]\n",
        "labels = [1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ],
      "metadata": {
        "id": "UOgYYQOVEEmd"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preparing data**\n",
        "*   For training a neural network model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xL06ud6OrKRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(code_samples)\n",
        "sequences = tokenizer.texts_to_sequences(code_samples)\n",
        "max_sequence_length = max(len(seq) for seq in sequences)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)"
      ],
      "metadata": {
        "id": "nOw6wovcEHKn"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LSTM Model**\n",
        "\n",
        "\n",
        "* Creation, Compilation, Training,Prediction\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KlsMDZ9wrtwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and compile the LSTM model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=max_sequence_length),\n",
        "    keras.layers.LSTM(128),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "X = np.array(padded_sequences)\n",
        "y_true = np.array(labels)\n",
        "model.fit(X, y_true, epochs=30, validation_split=0.2)\n",
        "\n",
        "# Example code snippet to predict\n",
        "example_code = [\"while True:\\n    print('Infinite loop')\"]\n",
        "\n",
        "# Tokenize and pad the example code\n",
        "example_sequence = tokenizer.texts_to_sequences(example_code)\n",
        "example_padded = pad_sequences(example_sequence, maxlen=max_sequence_length)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_proba = model.predict(np.array(example_padded))\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_true, model.predict(X).round())\n",
        "precision = precision_score(y_true, model.predict(X).round())\n",
        "recall = recall_score(y_true, model.predict(X).round())\n",
        "f1_lstm = f1_score(y_true, model.predict(X).round())\n",
        "conf_matrix = confusion_matrix(y_true, model.predict(X).round())\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1_lstm:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Print the prediction for the example code snippet\n",
        "lstm_predi=print(\"Example Code Prediction for lstm model :\",y_pred_proba)\n",
        "\n",
        "if y_pred > 0.5:\n",
        "    print(\"The provided code has correct syntax.\")\n",
        "else:\n",
        "    print(\"The provided code has syntax errors.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMyW5ptpv6Ar",
        "outputId": "2ee19378-dfd1-4437-eaf3-4d2cb7bde038"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6939 - accuracy: 0.4118 - val_loss: 0.7077 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.6870 - accuracy: 0.6176 - val_loss: 0.7181 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.6818 - accuracy: 0.6176 - val_loss: 0.7340 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.6750 - accuracy: 0.6176 - val_loss: 0.7600 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.6661 - accuracy: 0.6176 - val_loss: 0.8024 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.6541 - accuracy: 0.6176 - val_loss: 0.8753 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6404 - accuracy: 0.6176 - val_loss: 1.0096 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.6367 - accuracy: 0.6176 - val_loss: 1.1274 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.6333 - accuracy: 0.6176 - val_loss: 1.1021 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.6265 - accuracy: 0.6176 - val_loss: 1.0847 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.6170 - accuracy: 0.6176 - val_loss: 1.1375 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.6116 - accuracy: 0.6176 - val_loss: 1.2560 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.6156 - accuracy: 0.6176 - val_loss: 1.3534 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.6179 - accuracy: 0.6176 - val_loss: 1.3915 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.6111 - accuracy: 0.6176 - val_loss: 1.2904 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.5851 - accuracy: 0.6176 - val_loss: 1.1294 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.5576 - accuracy: 0.6176 - val_loss: 1.0617 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.5417 - accuracy: 0.6471 - val_loss: 1.0180 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.5297 - accuracy: 0.6765 - val_loss: 0.9741 - val_accuracy: 0.1111\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.5182 - accuracy: 0.7059 - val_loss: 0.9381 - val_accuracy: 0.2222\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5080 - accuracy: 0.7647 - val_loss: 0.9242 - val_accuracy: 0.2222\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.4944 - accuracy: 0.7647 - val_loss: 0.9093 - val_accuracy: 0.2222\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.4811 - accuracy: 0.7941 - val_loss: 0.8898 - val_accuracy: 0.2222\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.4682 - accuracy: 0.8529 - val_loss: 0.8956 - val_accuracy: 0.2222\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4506 - accuracy: 0.8529 - val_loss: 0.9153 - val_accuracy: 0.2222\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4305 - accuracy: 0.8529 - val_loss: 0.9549 - val_accuracy: 0.2222\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.4073 - accuracy: 0.8529 - val_loss: 1.0531 - val_accuracy: 0.2222\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.3822 - accuracy: 0.8529 - val_loss: 1.3308 - val_accuracy: 0.2222\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.3731 - accuracy: 0.8235 - val_loss: 1.9522 - val_accuracy: 0.2222\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.4320 - accuracy: 0.7647 - val_loss: 1.7703 - val_accuracy: 0.2222\n",
            "1/1 [==============================] - 0s 466ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Accuracy: 0.6512\n",
            "Precision: 0.5938\n",
            "Recall: 0.9048\n",
            "F1 Score: 0.7170\n",
            "Confusion Matrix:\n",
            "[[ 9 13]\n",
            " [ 2 19]]\n",
            "Example Code Prediction for lstm model : [[0.5407442]]\n",
            "The provided code has correct syntax.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GRU Model**\n",
        "\n",
        "* Creation, Compilation, Training,Prediction"
      ],
      "metadata": {
        "id": "ZzeCUL-ewxO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and compile the GRU model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=max_sequence_length),\n",
        "    keras.layers.GRU(128),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "X = np.array(padded_sequences)\n",
        "y_true = np.array(labels)\n",
        "model.fit(X, y_true, epochs=30, validation_split=0.2)\n",
        "\n",
        "# Example code snippet to predict\n",
        "example_code = [\"while True:\\n    print('Infinite loop')\"]\n",
        "\n",
        "# Tokenize and pad the example code\n",
        "example_sequence = tokenizer.texts_to_sequences(example_code)\n",
        "example_padded = pad_sequences(example_sequence, maxlen=max_sequence_length)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_proba = model.predict(np.array(example_padded))\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_true, model.predict(X).round())\n",
        "precision = precision_score(y_true, model.predict(X).round())\n",
        "recall = recall_score(y_true, model.predict(X).round())\n",
        "f1_gru = f1_score(y_true, model.predict(X).round())\n",
        "conf_matrix = confusion_matrix(y_true, model.predict(X).round())\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1_gru:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Print the prediction for the example code snippet\n",
        "gru_predi=print(\"Example Code Prediction for gru model :\",y_pred_proba)\n",
        "\n",
        "if y_pred > 0.5:\n",
        "    print(\"The provided code has correct syntax.\")\n",
        "else:\n",
        "    print(\"The provided code has syntax errors.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1E9PUJoENSI",
        "outputId": "bf661c90-0dc9-49a3-cb9a-a40da7dbe1af"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "2/2 [==============================] - 3s 638ms/step - loss: 0.6945 - accuracy: 0.3824 - val_loss: 0.7152 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.6849 - accuracy: 0.6176 - val_loss: 0.7351 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.6772 - accuracy: 0.6176 - val_loss: 0.7550 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.6692 - accuracy: 0.6176 - val_loss: 0.7795 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.6612 - accuracy: 0.6176 - val_loss: 0.8094 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.6515 - accuracy: 0.6176 - val_loss: 0.8402 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.6426 - accuracy: 0.6176 - val_loss: 0.8515 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.6338 - accuracy: 0.6176 - val_loss: 0.8519 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.6263 - accuracy: 0.6176 - val_loss: 0.8640 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.6170 - accuracy: 0.6176 - val_loss: 0.8772 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.6060 - accuracy: 0.6176 - val_loss: 0.9067 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.5913 - accuracy: 0.6176 - val_loss: 0.9723 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.5744 - accuracy: 0.6176 - val_loss: 1.0991 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.5629 - accuracy: 0.6176 - val_loss: 1.2958 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5645 - accuracy: 0.6176 - val_loss: 1.5259 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.5924 - accuracy: 0.6176 - val_loss: 1.4762 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5584 - accuracy: 0.6176 - val_loss: 1.2442 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.5081 - accuracy: 0.7059 - val_loss: 1.0900 - val_accuracy: 0.1111\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.4888 - accuracy: 0.7353 - val_loss: 0.9960 - val_accuracy: 0.1111\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4728 - accuracy: 0.7941 - val_loss: 0.9460 - val_accuracy: 0.1111\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4609 - accuracy: 0.8529 - val_loss: 0.9115 - val_accuracy: 0.2222\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.4495 - accuracy: 0.9118 - val_loss: 0.8901 - val_accuracy: 0.2222\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.4355 - accuracy: 0.9118 - val_loss: 0.8865 - val_accuracy: 0.2222\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.4186 - accuracy: 0.9118 - val_loss: 0.8989 - val_accuracy: 0.2222\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4010 - accuracy: 0.9118 - val_loss: 0.9241 - val_accuracy: 0.2222\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.3822 - accuracy: 0.9118 - val_loss: 0.9587 - val_accuracy: 0.2222\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.3625 - accuracy: 0.9118 - val_loss: 1.0054 - val_accuracy: 0.2222\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.3452 - accuracy: 0.9118 - val_loss: 1.0443 - val_accuracy: 0.2222\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.3270 - accuracy: 0.9118 - val_loss: 1.0522 - val_accuracy: 0.2222\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.3121 - accuracy: 0.9118 - val_loss: 1.0458 - val_accuracy: 0.2222\n",
            "1/1 [==============================] - 1s 649ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Accuracy: 0.7674\n",
            "Precision: 0.6897\n",
            "Recall: 0.9524\n",
            "F1 Score: 0.8000\n",
            "Confusion Matrix:\n",
            "[[13  9]\n",
            " [ 1 20]]\n",
            "Example Code Prediction for gru model : [[0.3063703]]\n",
            "The provided code has syntax errors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Simple RNN**\n",
        "\n",
        "* Creation, Compilation, Training,Prediction"
      ],
      "metadata": {
        "id": "hE0cIjiazo8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and compile the SimpleRNN model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=max_sequence_length),\n",
        "    keras.layers.SimpleRNN(128),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "X = np.array(padded_sequences)\n",
        "y_true = np.array(labels)\n",
        "model.fit(X, y_true, epochs=30, validation_split=0.2)\n",
        "\n",
        "# Example code snippet to predict\n",
        "example_code = [\"while True:\\n    print('Infinite loop')\"]\n",
        "\n",
        "# Tokenize and pad the example code\n",
        "example_sequence = tokenizer.texts_to_sequences(example_code)\n",
        "example_padded = pad_sequences(example_sequence, maxlen=max_sequence_length)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_proba = model.predict(np.array(example_padded))\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_true, model.predict(X).round())\n",
        "precision = precision_score(y_true, model.predict(X).round())\n",
        "recall = recall_score(y_true, model.predict(X).round())\n",
        "f1_simplernn = f1_score(y_true, model.predict(X).round())\n",
        "conf_matrix = confusion_matrix(y_true, model.predict(X).round())\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1_simplernn:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Print the prediction for the example code snippet\n",
        "simplernn_predi=print(\"Example Code Prediction for simple rnn model :\",y_pred_proba)\n",
        "\n",
        "if y_pred > 0.5:\n",
        "    print(\"The provided code has correct syntax.\")\n",
        "else:\n",
        "    print(\"The provided code has syntax errors.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IwUGnJZEQik",
        "outputId": "bea7effa-b188-43d9-fbf0-de8c60a7cb04"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "2/2 [==============================] - 2s 337ms/step - loss: 0.6827 - accuracy: 0.5294 - val_loss: 1.1893 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.6545 - accuracy: 0.6176 - val_loss: 1.1429 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.6189 - accuracy: 0.6176 - val_loss: 0.9055 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.5818 - accuracy: 0.6471 - val_loss: 0.7663 - val_accuracy: 0.2222\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5747 - accuracy: 0.8824 - val_loss: 0.7045 - val_accuracy: 0.4444\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5591 - accuracy: 0.8824 - val_loss: 0.6945 - val_accuracy: 0.5556\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.5343 - accuracy: 0.8824 - val_loss: 0.6823 - val_accuracy: 0.5556\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5086 - accuracy: 0.8824 - val_loss: 0.6418 - val_accuracy: 0.6667\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.4902 - accuracy: 0.8824 - val_loss: 0.6114 - val_accuracy: 0.6667\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.4700 - accuracy: 0.8824 - val_loss: 0.6469 - val_accuracy: 0.6667\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.4356 - accuracy: 0.8824 - val_loss: 0.7634 - val_accuracy: 0.5556\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.3989 - accuracy: 0.8529 - val_loss: 0.9123 - val_accuracy: 0.2222\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.3651 - accuracy: 0.9118 - val_loss: 1.0885 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.3488 - accuracy: 0.8824 - val_loss: 1.2504 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.3369 - accuracy: 0.8529 - val_loss: 1.2357 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.3148 - accuracy: 0.8824 - val_loss: 1.1583 - val_accuracy: 0.2222\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.2912 - accuracy: 0.9118 - val_loss: 1.1263 - val_accuracy: 0.3333\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.2723 - accuracy: 0.9118 - val_loss: 1.1189 - val_accuracy: 0.3333\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.2563 - accuracy: 0.9118 - val_loss: 1.1161 - val_accuracy: 0.3333\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.2437 - accuracy: 0.9118 - val_loss: 0.9998 - val_accuracy: 0.3333\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2471 - accuracy: 0.9118 - val_loss: 0.9717 - val_accuracy: 0.4444\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2365 - accuracy: 0.9118 - val_loss: 1.1413 - val_accuracy: 0.3333\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2140 - accuracy: 0.9118 - val_loss: 1.2882 - val_accuracy: 0.2222\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2057 - accuracy: 0.9118 - val_loss: 1.4096 - val_accuracy: 0.2222\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2034 - accuracy: 0.9118 - val_loss: 1.3554 - val_accuracy: 0.2222\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.1964 - accuracy: 0.9118 - val_loss: 1.2001 - val_accuracy: 0.3333\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.2051 - accuracy: 0.9118 - val_loss: 1.1430 - val_accuracy: 0.3333\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.2183 - accuracy: 0.9118 - val_loss: 1.1581 - val_accuracy: 0.3333\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.2248 - accuracy: 0.9118 - val_loss: 1.2347 - val_accuracy: 0.3333\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2246 - accuracy: 0.9118 - val_loss: 1.2472 - val_accuracy: 0.3333\n",
            "1/1 [==============================] - 0s 184ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Accuracy: 0.7907\n",
            "Precision: 0.7308\n",
            "Recall: 0.9048\n",
            "F1 Score: 0.8085\n",
            "Confusion Matrix:\n",
            "[[15  7]\n",
            " [ 2 19]]\n",
            "Example Code Prediction for simple rnn model : [[0.0364377]]\n",
            "The provided code has syntax errors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bidirectional RNN**\n",
        "\n",
        "* Creation, Compilation, Training,Prediction"
      ],
      "metadata": {
        "id": "G3yLntcv0GsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and compile the Bidirectional SimpleRNN model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=max_sequence_length),\n",
        "    keras.layers.Bidirectional(keras.layers.SimpleRNN(128)),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "X = np.array(padded_sequences)\n",
        "y_true = np.array(labels)\n",
        "model.fit(X, y_true, epochs=30, validation_split=0.2)\n",
        "\n",
        "# Example code snippet to predict\n",
        "example_code = [\"while True:\\n    print('Infinite loop')\"]\n",
        "\n",
        "# Tokenize and pad the example code\n",
        "example_sequence = tokenizer.texts_to_sequences(example_code)\n",
        "example_padded = pad_sequences(example_sequence, maxlen=max_sequence_length)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_proba = model.predict(np.array(example_padded))\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_true, model.predict(X).round())\n",
        "precision = precision_score(y_true, model.predict(X).round())\n",
        "recall = recall_score(y_true, model.predict(X).round())\n",
        "f1_biDrnn = f1_score(y_true, model.predict(X).round())\n",
        "conf_matrix = confusion_matrix(y_true, model.predict(X).round())\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1_biDrnn:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Print the prediction for the example code snippet\n",
        "BiDrnn_predi=print(\"Example Code Prediction for BiDrnn model :\",y_pred_proba)\n",
        "\n",
        "if y_pred > 0.5:\n",
        "    print(\"The provided code has correct syntax.\")\n",
        "else:\n",
        "    print(\"The provided code has syntax errors.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcGpLK6lETRC",
        "outputId": "174ec68f-2583-4103-c13d-f5c03f0e3f26"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "2/2 [==============================] - 3s 454ms/step - loss: 0.6668 - accuracy: 0.6765 - val_loss: 1.1830 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.6240 - accuracy: 0.6176 - val_loss: 1.2116 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.5778 - accuracy: 0.6471 - val_loss: 1.0132 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5117 - accuracy: 0.7059 - val_loss: 0.9106 - val_accuracy: 0.2222\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.4609 - accuracy: 0.8235 - val_loss: 0.8131 - val_accuracy: 0.2222\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.4364 - accuracy: 0.8824 - val_loss: 0.7615 - val_accuracy: 0.2222\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.3878 - accuracy: 0.9118 - val_loss: 0.7894 - val_accuracy: 0.3333\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.3508 - accuracy: 0.8824 - val_loss: 0.9252 - val_accuracy: 0.2222\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.3177 - accuracy: 0.8824 - val_loss: 1.1301 - val_accuracy: 0.2222\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.3038 - accuracy: 0.8824 - val_loss: 1.2701 - val_accuracy: 0.1111\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.2784 - accuracy: 0.8824 - val_loss: 1.3154 - val_accuracy: 0.2222\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.2516 - accuracy: 0.8824 - val_loss: 1.3735 - val_accuracy: 0.2222\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.2289 - accuracy: 0.8824 - val_loss: 1.4502 - val_accuracy: 0.2222\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.2151 - accuracy: 0.8824 - val_loss: 1.5759 - val_accuracy: 0.2222\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1990 - accuracy: 0.8824 - val_loss: 1.7417 - val_accuracy: 0.2222\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1883 - accuracy: 0.8824 - val_loss: 1.9052 - val_accuracy: 0.2222\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1821 - accuracy: 0.8824 - val_loss: 2.0542 - val_accuracy: 0.2222\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.1911 - accuracy: 0.9118 - val_loss: 2.0821 - val_accuracy: 0.2222\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.1940 - accuracy: 0.9118 - val_loss: 1.9115 - val_accuracy: 0.2222\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.2027 - accuracy: 0.8824 - val_loss: 1.7067 - val_accuracy: 0.2222\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.2126 - accuracy: 0.8824 - val_loss: 1.5728 - val_accuracy: 0.2222\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.2310 - accuracy: 0.8824 - val_loss: 1.4861 - val_accuracy: 0.2222\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.2446 - accuracy: 0.8824 - val_loss: 1.4265 - val_accuracy: 0.2222\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.2517 - accuracy: 0.8824 - val_loss: 1.3867 - val_accuracy: 0.2222\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.2530 - accuracy: 0.8824 - val_loss: 1.3767 - val_accuracy: 0.2222\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.2245 - accuracy: 0.8824 - val_loss: 1.3937 - val_accuracy: 0.2222\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.2057 - accuracy: 0.9118 - val_loss: 1.4154 - val_accuracy: 0.1111\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.2054 - accuracy: 0.9118 - val_loss: 1.4334 - val_accuracy: 0.1111\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.2233 - accuracy: 0.9118 - val_loss: 1.4097 - val_accuracy: 0.1111\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.2240 - accuracy: 0.9118 - val_loss: 1.3679 - val_accuracy: 0.1111\n",
            "1/1 [==============================] - 0s 278ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Accuracy: 0.7442\n",
            "Precision: 0.6786\n",
            "Recall: 0.9048\n",
            "F1 Score: 0.7755\n",
            "Confusion Matrix:\n",
            "[[13  9]\n",
            " [ 2 19]]\n",
            "Example Code Prediction for BiDrnn model : [[0.09319881]]\n",
            "The provided code has syntax errors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Stacked RNN**\n",
        "\n",
        "* Creation, Compilation, Training,Prediction"
      ],
      "metadata": {
        "id": "XgnWUlfm0ekO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and compile the stacked SimpleRNN model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=max_sequence_length),\n",
        "    keras.layers.SimpleRNN(64, return_sequences=True),\n",
        "    keras.layers.SimpleRNN(64),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "X = np.array(padded_sequences)\n",
        "y_true = np.array(labels)\n",
        "model.fit(X, y_true, epochs=30, validation_split=0.2)\n",
        "\n",
        "# Example code snippet to predict\n",
        "example_code = [\"while True:\\n    print('Infinite loop')\"]\n",
        "\n",
        "# Tokenize and pad the example code\n",
        "example_sequence = tokenizer.texts_to_sequences(example_code)\n",
        "example_padded = pad_sequences(example_sequence, maxlen=max_sequence_length)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_proba = model.predict(np.array(example_padded))\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_true, model.predict(X).round())\n",
        "precision = precision_score(y_true, model.predict(X).round())\n",
        "recall = recall_score(y_true, model.predict(X).round())\n",
        "f1_stackedrnn = f1_score(y_true, model.predict(X).round())\n",
        "conf_matrix = confusion_matrix(y_true, model.predict(X).round())\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1_stackedrnn:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Print the prediction for the example code snippet\n",
        "stackedrnn_predi=print(\"Example Code Prediction for stackedrnn model :\",y_pred_proba)\n",
        "\n",
        "if y_pred > 0.5:\n",
        "    print(\"The provided code has correct syntax.\")\n",
        "else:\n",
        "    print(\"The provided code has syntax errors.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx6JsezoEWjm",
        "outputId": "c3473331-8a8e-4729-e809-8f9f24fe21a9"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "2/2 [==============================] - 5s 500ms/step - loss: 0.6514 - accuracy: 0.6176 - val_loss: 1.5968 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.6805 - accuracy: 0.6176 - val_loss: 1.4173 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.6030 - accuracy: 0.6176 - val_loss: 0.9682 - val_accuracy: 0.1111\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.5321 - accuracy: 0.8235 - val_loss: 0.7363 - val_accuracy: 0.4444\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.5189 - accuracy: 0.8235 - val_loss: 0.6489 - val_accuracy: 0.6667\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.5118 - accuracy: 0.7647 - val_loss: 0.5904 - val_accuracy: 0.7778\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.5075 - accuracy: 0.7353 - val_loss: 0.6175 - val_accuracy: 0.6667\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4694 - accuracy: 0.7647 - val_loss: 0.6852 - val_accuracy: 0.5556\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.4202 - accuracy: 0.7941 - val_loss: 0.7623 - val_accuracy: 0.5556\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.3761 - accuracy: 0.8235 - val_loss: 0.9027 - val_accuracy: 0.4444\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.3371 - accuracy: 0.8529 - val_loss: 1.0508 - val_accuracy: 0.3333\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.3042 - accuracy: 0.8824 - val_loss: 1.1424 - val_accuracy: 0.2222\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.2830 - accuracy: 0.9118 - val_loss: 1.2690 - val_accuracy: 0.2222\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.2669 - accuracy: 0.9118 - val_loss: 1.4021 - val_accuracy: 0.2222\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.2534 - accuracy: 0.9118 - val_loss: 1.4861 - val_accuracy: 0.2222\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.2413 - accuracy: 0.9118 - val_loss: 1.5003 - val_accuracy: 0.2222\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.2272 - accuracy: 0.9118 - val_loss: 1.4593 - val_accuracy: 0.2222\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.2134 - accuracy: 0.9118 - val_loss: 1.4029 - val_accuracy: 0.3333\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.2107 - accuracy: 0.9118 - val_loss: 1.4390 - val_accuracy: 0.3333\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.2027 - accuracy: 0.9118 - val_loss: 1.6565 - val_accuracy: 0.3333\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.2156 - accuracy: 0.9118 - val_loss: 1.7269 - val_accuracy: 0.3333\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.2062 - accuracy: 0.9118 - val_loss: 1.6025 - val_accuracy: 0.3333\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.1917 - accuracy: 0.9118 - val_loss: 1.5059 - val_accuracy: 0.3333\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.1933 - accuracy: 0.8824 - val_loss: 1.4402 - val_accuracy: 0.3333\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.2026 - accuracy: 0.8824 - val_loss: 1.4162 - val_accuracy: 0.3333\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.2110 - accuracy: 0.8824 - val_loss: 1.3549 - val_accuracy: 0.3333\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.2205 - accuracy: 0.8824 - val_loss: 1.2638 - val_accuracy: 0.5556\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.2388 - accuracy: 0.8824 - val_loss: 1.2264 - val_accuracy: 0.5556\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.2480 - accuracy: 0.8529 - val_loss: 1.2348 - val_accuracy: 0.5556\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.2423 - accuracy: 0.8824 - val_loss: 1.2981 - val_accuracy: 0.4444\n",
            "1/1 [==============================] - 0s 448ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Accuracy: 0.7907\n",
            "Precision: 0.7727\n",
            "Recall: 0.8095\n",
            "F1 Score: 0.7907\n",
            "Confusion Matrix:\n",
            "[[17  5]\n",
            " [ 4 17]]\n",
            "Example Code Prediction for stackedrnn model : [[0.0127044]]\n",
            "The provided code has syntax errors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1D CNN**\n",
        "\n",
        "* Creation, Compilation, Training,Prediction"
      ],
      "metadata": {
        "id": "G4UdaHTz1Hc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and compile the 1D CNN model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=max_sequence_length),\n",
        "    keras.layers.Conv1D(128, 5, activation='relu'),\n",
        "    keras.layers.GlobalMaxPooling1D(),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "X = np.array(padded_sequences)\n",
        "y_true = np.array(labels)\n",
        "model.fit(X, y_true, epochs=5, validation_split=0.2)\n",
        "\n",
        "# Example code snippet to predict\n",
        "example_code = [\"while True:\\n    print('Infinite loop')\"]\n",
        "example_sequence = tokenizer.texts_to_sequences(example_code)\n",
        "example_padded = pad_sequences(example_sequence, maxlen=max_sequence_length)\n",
        "y_pred_proba = model.predict(np.array(example_padded))\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_true, model.predict(X).round())\n",
        "precision = precision_score(y_true, model.predict(X).round())\n",
        "recall = recall_score(y_true, model.predict(X).round())\n",
        "f1_1Dcnn = f1_score(y_true, model.predict(X).round())\n",
        "conf_matrix = confusion_matrix(y_true, model.predict(X).round())\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1_1Dcnn:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Print the prediction for the example code snippet\n",
        "oneDcnn_predi=print(\"Example Code Prediction for 1Dcnn model :\",y_pred_proba)\n",
        "if y_pred > 0.5:\n",
        "    print(\"The provided code has correct syntax.\")\n",
        "else:\n",
        "    print(\"The provided code has syntax errors.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrHLNMBeEYyH",
        "outputId": "beb19594-e724-4d1a-e311-9c50d48ac5a8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "2/2 [==============================] - 2s 345ms/step - loss: 0.6931 - accuracy: 0.4412 - val_loss: 0.7223 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.6718 - accuracy: 0.6176 - val_loss: 0.7398 - val_accuracy: 0.1111\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.6592 - accuracy: 0.6765 - val_loss: 0.7420 - val_accuracy: 0.1111\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.6488 - accuracy: 0.7647 - val_loss: 0.7310 - val_accuracy: 0.2222\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.6421 - accuracy: 0.8235 - val_loss: 0.7300 - val_accuracy: 0.2222\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Accuracy: 0.6977\n",
            "Precision: 0.6333\n",
            "Recall: 0.9048\n",
            "F1 Score: 0.7451\n",
            "Confusion Matrix:\n",
            "[[11 11]\n",
            " [ 2 19]]\n",
            "Example Code Prediction for 1Dcnn model : [[0.48416036]]\n",
            "The provided code has syntax errors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Attention Mechanism**"
      ],
      "metadata": {
        "id": "YXPgxC6m1dWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(code_samples, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load the BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "\n",
        "# Tokenize the input sequences\n",
        "X_train_encodings = tokenizer(list(X_train), truncation=True, padding=True, return_tensors=\"tf\")\n",
        "X_val_encodings = tokenizer(list(X_val), truncation=True, padding=True, return_tensors=\"tf\")\n",
        "\n",
        "# Create TensorFlow datasets with tuple structure (input_dict, labels)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((dict(X_train_encodings), y_train)).shuffle(100).batch(16)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((dict(X_val_encodings), y_val)).batch(64)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=2e-5), loss=SparseCategoricalCrossentropy(from_logits=True), metrics=[SparseCategoricalAccuracy()])\n",
        "\n",
        "# Fine-tune the model on your data\n",
        "model.fit(train_dataset, validation_data=val_dataset, epochs=3)\n",
        "\n",
        "# Evaluate the model\n",
        "y_val_pred_logits = model.predict(dict(X_val_encodings))\n",
        "y_val_pred = np.argmax(y_val_pred_logits.logits, axis=1)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_val, y_val_pred)\n",
        "precision = precision_score(y_val, y_val_pred)\n",
        "recall = recall_score(y_val, y_val_pred)\n",
        "f1_attentionmech = f1_score(y_val, y_val_pred)\n",
        "conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1_attentionmech:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Example code snippet to predict\n",
        "example_code = [\"while True:\\n    print('Infinite loop')\"]\n",
        "example_encodings = tokenizer(example_code, truncation=True, padding=True, return_tensors=\"tf\")\n",
        "example_prediction_logits = model.predict(dict(example_encodings))\n",
        "\n",
        "if np.argmax(example_prediction_logits.logits, axis=1) == 1:\n",
        "    print(\"The provided code has correct syntax.\")\n",
        "else:\n",
        "    print(\"The provided code has syntax errors.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPgezE7cEb6E",
        "outputId": "b2b7dd01-e4fb-4302-b759-2d52c66cbf49"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "3/3 [==============================] - 56s 7s/step - loss: 0.7140 - sparse_categorical_accuracy: 0.5000 - val_loss: 0.6770 - val_sparse_categorical_accuracy: 0.5556\n",
            "Epoch 2/3\n",
            "3/3 [==============================] - 15s 4s/step - loss: 0.7143 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6874 - val_sparse_categorical_accuracy: 0.5556\n",
            "Epoch 3/3\n",
            "3/3 [==============================] - 14s 5s/step - loss: 0.7045 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6872 - val_sparse_categorical_accuracy: 0.5556\n",
            "1/1 [==============================] - 5s 5s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5556\n",
            "Precision: 0.0000\n",
            "Recall: 0.0000\n",
            "F1 Score: 0.0000\n",
            "Confusion Matrix:\n",
            "[[5 0]\n",
            " [4 0]]\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "The provided code has syntax errors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print F1 scores for each model\n",
        "print(f\"F1 Score (LSTM): {f1_lstm:.4f}\")\n",
        "print(f\"F1 Score (GRU): {f1_gru:.4f}\")\n",
        "print(f\"F1 Score (SimpleRNN): {f1_simplernn:.4f}\")\n",
        "print(f\"F1 Score (Bidirectional RNN): {f1_biDrnn:.4f}\")\n",
        "print(f\"F1 Score (Stacked RNN): {f1_stackedrnn:.4f}\")\n",
        "print(f\"F1 Score (1D CNN): {f1_1Dcnn:.4f}\")\n",
        "print(f\"F1 Score (Attention Mechanism): {f1_attentionmech:.4f}\")\n",
        "\n",
        "# Find the model with the maximum F1 score\n",
        "models = [\"LSTM\", \"GRU\", \"SimpleRNN\", \"Bidirectional RNN\", \"Stacked RNN\", \"1D CNN\", \"Attention Mechanism\"]\n",
        "f1_scores = [f1_lstm, f1_gru, f1_simplernn, f1_biDrnn, f1_stackedrnn, f1_1Dcnn, f1_attentionmech]\n",
        "\n",
        "max_f1_score = max(f1_scores)\n",
        "max_f1_index = f1_scores.index(max_f1_score)\n",
        "best_model = models[max_f1_index]\n",
        "\n",
        "# Print the model with the maximum F1 score\n",
        "print(f\"\\nModel with the Maximum F1 Score: {best_model} ({max_f1_score:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TGAmyrb7QB4",
        "outputId": "3a243f02-6dff-4b6b-c30e-f93fae55bb6f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score (LSTM): 0.7755\n",
            "F1 Score (GRU): 0.8000\n",
            "F1 Score (SimpleRNN): 0.8085\n",
            "F1 Score (Bidirectional RNN): 0.7755\n",
            "F1 Score (Stacked RNN): 0.7907\n",
            "F1 Score (1D CNN): 0.7451\n",
            "F1 Score (Attention Mechanism): 0.0000\n",
            "\n",
            "Model with the Maximum F1 Score: SimpleRNN (0.8085)\n"
          ]
        }
      ]
    }
  ]
}